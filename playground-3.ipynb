{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-29T10:11:43.931200Z","iopub.execute_input":"2023-06-29T10:11:43.931629Z","iopub.status.idle":"2023-06-29T10:11:43.941910Z","shell.execute_reply.started":"2023-06-29T10:11:43.931595Z","shell.execute_reply":"2023-06-29T10:11:43.940563Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e18/sample_submission.csv\n/kaggle/input/playground-series-s3e18/train.csv\n/kaggle/input/playground-series-s3e18/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e18/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e18/test.csv')\nfrom scipy.stats import pearsonr\n\n# Calculate correlation between EC1 and EC2\ncorr, _ = pearsonr(train['EC1'], train['EC2'])\n\n# Since correlation is low at -0.146, we attempt to treat the two labels as independent\nX = train.drop(['id', 'EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis = 1)\ny1 = train['EC1']\ny2 = train['EC2']\n\ntest.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:12:50.935369Z","iopub.execute_input":"2023-06-29T10:12:50.935884Z","iopub.status.idle":"2023-06-29T10:12:51.260941Z","shell.execute_reply.started":"2023-06-29T10:12:50.935837Z","shell.execute_reply":"2023-06-29T10:12:51.259487Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"      id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n      Chi2v  \\\n0  14838   344.632371   7.283603   4.473966   5.834958   3.412257   4.651530   \n1  14839  1432.410201  10.663869   7.079026   8.065215   5.297097   5.297097   \n2  14840    83.352608   3.931852   1.774215   1.774215   1.073446   1.073446   \n3  14841   150.255712   5.912790   3.548812   3.548812   2.595128   2.595128   \n4  14842  1817.276351  24.910940  15.540529  20.047314  12.535886  17.730988   \n\n       Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA14  PEOE_VSA6  PEOE_VSA7  \\\n0   2.096558  1.116433    49.458581  ...   13.512441   0.000000   0.000000   \n1   3.924155  2.569694     0.000000  ...    0.000000  34.947374  98.323987   \n2   0.467830  0.170838     5.969305  ...    5.969305   0.000000   0.000000   \n3   1.642813  0.694113     0.000000  ...   59.935299   0.000000   0.000000   \n4  11.979618  4.431173    84.554972  ...   23.468091  25.609359   0.000000   \n\n   PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  fr_COO2  \n0   0.000000  26.809272  24.539800    4.794537    47.304082       1        1  \n1   9.606882   0.000000  53.378235    0.000000    43.166667       0        0  \n2   6.420822  11.752550  13.344559    9.589074    24.666667       1        1  \n3   0.000000  17.744066  32.290168    4.794537    26.778866       0        0  \n4  37.099000  69.141353  38.704130   50.697492   102.583333       0        0  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>BertzCT</th>\n      <th>Chi1</th>\n      <th>Chi1n</th>\n      <th>Chi1v</th>\n      <th>Chi2n</th>\n      <th>Chi2v</th>\n      <th>Chi3v</th>\n      <th>Chi4n</th>\n      <th>EState_VSA1</th>\n      <th>...</th>\n      <th>PEOE_VSA14</th>\n      <th>PEOE_VSA6</th>\n      <th>PEOE_VSA7</th>\n      <th>PEOE_VSA8</th>\n      <th>SMR_VSA10</th>\n      <th>SMR_VSA5</th>\n      <th>SlogP_VSA3</th>\n      <th>VSA_EState9</th>\n      <th>fr_COO</th>\n      <th>fr_COO2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14838</td>\n      <td>344.632371</td>\n      <td>7.283603</td>\n      <td>4.473966</td>\n      <td>5.834958</td>\n      <td>3.412257</td>\n      <td>4.651530</td>\n      <td>2.096558</td>\n      <td>1.116433</td>\n      <td>49.458581</td>\n      <td>...</td>\n      <td>13.512441</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>26.809272</td>\n      <td>24.539800</td>\n      <td>4.794537</td>\n      <td>47.304082</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14839</td>\n      <td>1432.410201</td>\n      <td>10.663869</td>\n      <td>7.079026</td>\n      <td>8.065215</td>\n      <td>5.297097</td>\n      <td>5.297097</td>\n      <td>3.924155</td>\n      <td>2.569694</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>34.947374</td>\n      <td>98.323987</td>\n      <td>9.606882</td>\n      <td>0.000000</td>\n      <td>53.378235</td>\n      <td>0.000000</td>\n      <td>43.166667</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14840</td>\n      <td>83.352608</td>\n      <td>3.931852</td>\n      <td>1.774215</td>\n      <td>1.774215</td>\n      <td>1.073446</td>\n      <td>1.073446</td>\n      <td>0.467830</td>\n      <td>0.170838</td>\n      <td>5.969305</td>\n      <td>...</td>\n      <td>5.969305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.420822</td>\n      <td>11.752550</td>\n      <td>13.344559</td>\n      <td>9.589074</td>\n      <td>24.666667</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14841</td>\n      <td>150.255712</td>\n      <td>5.912790</td>\n      <td>3.548812</td>\n      <td>3.548812</td>\n      <td>2.595128</td>\n      <td>2.595128</td>\n      <td>1.642813</td>\n      <td>0.694113</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>59.935299</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.744066</td>\n      <td>32.290168</td>\n      <td>4.794537</td>\n      <td>26.778866</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14842</td>\n      <td>1817.276351</td>\n      <td>24.910940</td>\n      <td>15.540529</td>\n      <td>20.047314</td>\n      <td>12.535886</td>\n      <td>17.730988</td>\n      <td>11.979618</td>\n      <td>4.431173</td>\n      <td>84.554972</td>\n      <td>...</td>\n      <td>23.468091</td>\n      <td>25.609359</td>\n      <td>0.000000</td>\n      <td>37.099000</td>\n      <td>69.141353</td>\n      <td>38.704130</td>\n      <td>50.697492</td>\n      <td>102.583333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split into training and validation set\nX1_train, X1_val, y1_train, y1_val = train_test_split(X, y1)\nX2_train, X2_val, y2_train, y2_val = train_test_split(X, y2)","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:11:44.183058Z","iopub.execute_input":"2023-06-29T10:11:44.184627Z","iopub.status.idle":"2023-06-29T10:11:44.214315Z","shell.execute_reply.started":"2023-06-29T10:11:44.184558Z","shell.execute_reply":"2023-06-29T10:11:44.212742Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:11:44.216681Z","iopub.execute_input":"2023-06-29T10:11:44.217553Z","iopub.status.idle":"2023-06-29T10:11:57.553444Z","shell.execute_reply.started":"2023-06-29T10:11:44.217479Z","shell.execute_reply":"2023-06-29T10:11:57.552071Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.2.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.11.1)\nRequirement already satisfied: cmaes>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from optuna) (0.9.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.7.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.12)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.64.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (5.4.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Flag for optimisation loop\nflag = False\n\n# Use optuna to find optimal no. of features to extract, and best XGBoost hyperparams\nimport optuna\n\n# For EC1\ndef objective(trial):\n    \n    num_features = trial.suggest_int('num_features', 10, 31)\n    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n    max_depth = trial.suggest_int('max_depth', 1, 15)\n    learning_rate = trial.suggest_float('learning_rate', 0.0001, 0.01, log=True)\n    gamma = trial.suggest_float('gamma', 0, 10)\n    subsample = trial.suggest_float('subsample', 0.5, 1)\n    \n    # Select top num_features most relevant features\n    fvalue_selector1 = SelectKBest(f_classif, k=num_features)\n\n    # Apply the SelectKBest object to the features and target\n    X_kbest1 = pd.DataFrame(fvalue_selector1.fit_transform(X1_train.copy(), y1_train))\n    \n    \n    XGB = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, eta=learning_rate, objective='binary:logistic', gamma=gamma, subsample=subsample)\n    # fit model\n    XGB.fit(X_kbest1, y1_train)\n    \n    # Transform validation set and produce result\n    X_kbestval = pd.DataFrame(fvalue_selector1.transform(X1_val))\n    pred = XGB.predict(X_kbestval)\n    \n    try:\n        roc_auc = roc_auc_score(XGB.predict(X_kbestval), y1_val)\n    except:\n        return 0\n    else:\n        return roc_auc\n\n\nif flag:\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=20)\n    trial1 = study.best_trial\n\n\n    print('EC1 Best auc: {}'.format(trial1.value))\n    print(\"Best hyperparameters: {}\".format(trial1.params))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:11:57.556906Z","iopub.execute_input":"2023-06-29T10:11:57.557312Z","iopub.status.idle":"2023-06-29T10:11:57.570861Z","shell.execute_reply.started":"2023-06-29T10:11:57.557256Z","shell.execute_reply":"2023-06-29T10:11:57.569493Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# For EC2\ndef objective(trial):\n    \n    num_features = trial.suggest_int('num_features', 10, 15)\n    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n    max_depth = trial.suggest_int('max_depth', 1, 10)\n    learning_rate = trial.suggest_float('learning_rate', 0.0001, 0.01, log=True)\n    gamma = trial.suggest_float('gamma', 0, 10)\n    subsample = trial.suggest_float('subsample', 0.5, 1)\n    \n    # Select top num_features most relevant features\n    fvalue_selector2 = SelectKBest(f_classif, k=num_features)\n\n    # Apply the SelectKBest object to the features and target\n    X_kbest2 = pd.DataFrame(fvalue_selector2.fit_transform(X2_train.copy(), y2_train))\n    \n    \n    XGB = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, eta=learning_rate, objective='binary:logistic', gamma=gamma, subsample=subsample)\n    # fit model\n    XGB.fit(X_kbest2, y2_train)\n    \n    # Transform validation set and produce result\n    X_kbestval = pd.DataFrame(fvalue_selector2.transform(X2_val))\n    pred = XGB.predict(X_kbestval)\n    \n    try:\n        roc_auc = roc_auc_score(XGB.predict(X_kbestval), y2_val)\n    except:\n        return 0\n    else:\n        return roc_auc\n\nif flag:\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=20)\n    trial2 = study.best_trial\n\n\n    print('EC2 Best auc: {}'.format(trial2.value))\n    print(\"Best hyperparameters: {}\".format(trial2.params))","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:11:57.572304Z","iopub.execute_input":"2023-06-29T10:11:57.572750Z","iopub.status.idle":"2023-06-29T10:11:57.591488Z","shell.execute_reply.started":"2023-06-29T10:11:57.572715Z","shell.execute_reply":"2023-06-29T10:11:57.590186Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n# Best parameters for EC1, uses all 31 available features\nnum_features_EC1 = 31\nXGB1 = XGBClassifier(n_estimators=309, max_depth=3, eta=0.007895285421241401, objective='binary:logistic', gamma=2.0683433342683584, subsample=0.9913940145908703)\n\n# Best parameters for EC2, uses top 15 features\nnum_features_EC2 = 15\nXGB2 = XGBClassifier(n_estimators=991, max_depth=8, eta=0.002164036382215584, objective='binary:logistic', gamma=2.2947040482736365, subsample=0.9010902054341825)","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:11:57.592927Z","iopub.execute_input":"2023-06-29T10:11:57.593272Z","iopub.status.idle":"2023-06-29T10:11:57.608940Z","shell.execute_reply.started":"2023-06-29T10:11:57.593244Z","shell.execute_reply":"2023-06-29T10:11:57.607492Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_test = test.drop(['id'], axis = 1)\n\n# Final model and predictions\nXGB1.fit(X, y1)\npred_EC1 = XGB1.predict(X_test)\n\nfvalue_selector = SelectKBest(f_classif, k=num_features_EC2)\n# Apply the SelectKBest object to the features and target\nX_kbest = pd.DataFrame(fvalue_selector.fit_transform(X.copy(), y2))\nXGB2.fit(X_kbest, y2)\n\nX_kbest_test = pd.DataFrame(fvalue_selector.transform(X_test))\npred_EC2 = XGB2.predict(X_kbest_test)\n\noutput = pd.DataFrame({'id': test.id, 'EC1': pred_EC1, 'EC2':pred_EC2})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T10:13:06.646084Z","iopub.execute_input":"2023-06-29T10:13:06.646540Z","iopub.status.idle":"2023-06-29T10:13:29.170031Z","shell.execute_reply.started":"2023-06-29T10:13:06.646506Z","shell.execute_reply":"2023-06-29T10:13:29.168756Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Your submission was successfully saved!\n","output_type":"stream"}]}]}